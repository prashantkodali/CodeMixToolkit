{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314a3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79fd67",
   "metadata": {},
   "source": [
    "# CodeMixed Sentence Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9599d83",
   "metadata": {},
   "source": [
    "CodeMixSentence object serves as a comprehensive container for analyzing and quantifying code-mixing. It encapsulates \n",
    "- structural components of a sentence (tokens, language tags, part-of-speech tags) \n",
    "- various metrics that measure the degree and patterns of language mixing, such as Code-Mixing Index (CMI), burstiness, language entropy, and SyMCoM scores. \n",
    "\n",
    "The CodeMixSentence object provides a standardized framework for computing and storing code-mixing metrics, which is essential for several reasons:\n",
    "\n",
    "- Standardisation: Having a standardized format, capturing necessary attributes of a code-mixed sentence, makes it easier to share and compare results across different datasets, and across the research community.\n",
    "\n",
    "- Reproducibility & Consistency: By encapsulating all the metrics (CMI, burstiness, I-index, language entropy, etc.) in a single object with well-defined computation methods, it ensures that one can reproduce the same results when analyzing code-mixed text.\n",
    "\n",
    "- Extensibility: The object provides a clear structure for adding new metrics or modifying existing ones while maintaining compatibility with the established framework. This is important as the field of code-mixing research continues to evolve.\n",
    "\n",
    "\n",
    "The CodeMixSentence object provides a common ground for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66199363",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['Gully', 'cricket', 'चल', 'रहा', 'हैं', 'यहां', '\"', '(', 'Soniya', ')', 'Gandhi', '\"']\n",
    "LID_Tags = ['en', 'en', 'hi', 'hi', 'hi', 'hi', 'univ', 'univ', 'ne', 'univ', 'ne', 'univ']\n",
    "PoS_Tags = ['ADJ', 'PROPN', 'VERB', 'AUX', 'AUX', 'ADV', 'PUNCT', 'PUNCT', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT']\n",
    "\n",
    "lang_tags = ['hi', 'en']\n",
    "other_tags = ['univ', 'ne', 'acro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ead67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from codemix.cs_metrics import CodeMixSentence\n",
    "from codemixtoolkit import CodeMixSentence\n",
    "codemixed_sentence = CodeMixSentence(lang_tagset = lang_tags, \n",
    "                                    other_tagset = other_tags, \n",
    "                                    l1 = 'en', \n",
    "                                    l2 = 'hi', \n",
    "                                    sentence = None, \n",
    "                                    tokens = tokens, \n",
    "                                    LID_Tags = LID_Tags, \n",
    "                                    PoS_Tags = PoS_Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69dfb3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeMixSentenceCombined(\n",
      "    lang_tagset=['hi', 'en'],\n",
      "    other_tagset=['univ', 'ne', 'acro'],\n",
      "    l1='en',\n",
      "    l2='hi',\n",
      "    sentence='None',\n",
      "    tokens=['Gully', 'cricket', 'चल', 'रहा', 'हैं', 'यहां', '\"', '(', 'Soniya', ')', 'Gandhi', '\"'],\n",
      "    LID_Tags=['en', 'en', 'hi', 'hi', 'hi', 'hi'],\n",
      "    PoS_Tags=['ADJ', 'PROPN', 'VERB', 'AUX', 'AUX', 'ADV', 'PUNCT', 'PUNCT', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT'],\n",
      "    length=12,\n",
      "    cmi=None,\n",
      "    burstiness=None,\n",
      "    i_index=None,\n",
      "    lang_entropy=None,\n",
      "    mindex=None,\n",
      "    spavg=None,\n",
      "    symcom_sentence=None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(codemixed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8568788",
   "metadata": {},
   "source": [
    "# CodeMix Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4706e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeMixSentenceCombined(\n",
      "    lang_tagset=['hi', 'en'],\n",
      "    other_tagset=['univ', 'ne', 'acro'],\n",
      "    l1='en',\n",
      "    l2='hi',\n",
      "    sentence='None',\n",
      "    tokens=['Gully', 'cricket', 'चल', 'रहा', 'हैं', 'यहां', '\"', '(', 'Soniya', ')', 'Gandhi', '\"'],\n",
      "    LID_Tags=['en', 'en', 'hi', 'hi', 'hi', 'hi'],\n",
      "    PoS_Tags=['ADJ', 'PROPN', 'VERB', 'AUX', 'AUX', 'ADV', 'PUNCT', 'PUNCT', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT'],\n",
      "    length=12,\n",
      "    cmi=33.333333333333336,\n",
      "    burstiness=-0.3592455179659185,\n",
      "    i_index=0.2,\n",
      "    lang_entropy=0.9182958340544896,\n",
      "    mindex=0.7999999999999999,\n",
      "    spavg=1,\n",
      "    symcom_sentence=0.6666666666666666\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Computes all the metrics for the code-mixed sentence object which would have necessary fields like LID Tags and PoS Tags.\n",
    "'''\n",
    "\n",
    "codemixed_sentence.compute_all_metrics()\n",
    "print(codemixed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f01bbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI Score: 33.333333333333336\n",
      "M-index: 0.7999999999999999\n",
      "Language Entropy: 0.9182958340544896\n",
      "I-index: 0.18181818181818182\n",
      "Burstiness: -0.3592455179659185\n",
      "SyMCoM POS scores: {'PROPN_symcom': 1.0, 'AUX_symcom': -1.0, 'ADJ_symcom': 1.0, 'VERB_symcom': -1.0, 'ADV_symcom': -1.0}\n",
      "Overall SyMCoM score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# from codemix.cs_metrics import CodeMixMetrics\n",
    "from codemixtoolkit import CodeMixMetrics\n",
    "\n",
    "# Compute CMI (Code-Mixing Index)\n",
    "cmi_score = CodeMixMetrics.compute_cmi(lid_tags=LID_Tags, lang_tagset=['en', 'hi'])\n",
    "print(f\"CMI Score: {cmi_score}\")\n",
    "\n",
    "\n",
    "m_index = CodeMixMetrics.compute_mindex(lid_tags=LID_Tags, lang_tagset=['en', 'hi'])\n",
    "print(f\"M-index: {m_index}\")\n",
    "\n",
    "\n",
    "# Compute Language Entropy\n",
    "entropy = CodeMixMetrics.compute_lang_entropy(lid_tags=LID_Tags, lang_tagset=['en', 'hi'])\n",
    "print(f\"Language Entropy: {entropy}\")  \n",
    "\n",
    "# Compute I-index\n",
    "i_index = CodeMixMetrics.compute_i_index(lid_tags=LID_Tags, other_tagset=other_tags)\n",
    "print(f\"I-index: {i_index}\")  \n",
    "\n",
    "# Compute Burstiness\n",
    "burstiness = CodeMixMetrics.compute_burstiness(lid_tags=LID_Tags, other_tagset=other_tags)\n",
    "print(f\"Burstiness: {burstiness}\") \n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "LID_count_map = dict(Counter(LID_Tags).most_common())\n",
    "PoS_count_map = dict(Counter(PoS_Tags).most_common())\n",
    "\n",
    "lid_pos_combined = [pos + \"_\" + lid for lid, pos in zip(LID_Tags, PoS_Tags)]\n",
    "LID_POS_count_map = dict(Counter(lid_pos_combined).most_common())\n",
    "\n",
    "# Compute SyMCoM for POS tags\n",
    "symcom_pos = CodeMixMetrics.compute_symcom_pos_tags(poS_count_map=PoS_count_map, \n",
    "                                                    lid_pos_count_map=LID_POS_count_map, \n",
    "                                                    l1='en', l2='hi')\n",
    "print(f\"SyMCoM POS scores: {symcom_pos}\")  # Expected output: {'NOUN_symcom': 0.33, 'VERB_symcom': -1.0}\n",
    "\n",
    "# Compute overall SyMCoM score\n",
    "symcom_score = CodeMixMetrics.compute_symcom_sentence(poS_count_map=PoS_count_map, \n",
    "                                                      lid_pos_count_map = LID_POS_count_map, \n",
    "                                                      l1 = 'en', \n",
    "                                                      l2 = 'hi', \n",
    "                                                      length = len(LID_Tags))\n",
    "print(f\"Overall SyMCoM score: {symcom_score}\")  # Expected output: ~0.53\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a21ba",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8c9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codemixtoolkit import codemix_viz as cv\n",
    "\n",
    "annotation_printer = cv.AnnotatedTextPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40706eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#1f77b4;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">Gully<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">ADJ</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#1f77b4;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">cricket<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PROPN</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">चल<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">VERB</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">रहा<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">AUX</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">हैं<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">AUX</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">यहां<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">ADV</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">&quot;<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">(<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#7f7f7f;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">Soniya<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PROPN</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">)<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#7f7f7f;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">Gandhi<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PROPN</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">&quot;<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_printer.print_sample_st_annot_text(tokens, LID_Tags, PoS_Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b63669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file saved as codemix_visualization_test.html\n"
     ]
    }
   ],
   "source": [
    "annotation_printer.export_html(file_name=\"codemix_visualization_test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3445ad",
   "metadata": {},
   "source": [
    "# NER Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e79381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, 'ne', False, False, False, False, False, False]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codemixtoolkit.models import NERtagger\n",
    "\n",
    "ner_tagger = NERtagger(model_path=\"ai4bharat/IndicNER\", \n",
    "                       tokenizer_path=\"ai4bharat/IndicNER\")\n",
    "ner_tagger.load_model_tokenizer()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "predicted_ner_tags = ner_tagger.predict_ner_sentence(sentence)\n",
    "predicted_ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360871a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = NERtagger(model_path=\"ai4bharat/IndicNER\", \n",
    "                       tokenizer_path=\"ai4bharat/IndicNER\",\n",
    "                       finegrain_labels=True)\n",
    "ner_tagger.load_model_tokenizer()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "predicted_ner_tags = ner_tagger.predict_ner_sentence(sentence)\n",
    "predicted_ner_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec06275",
   "metadata": {},
   "source": [
    "# PoS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4261b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted POS tags: ['PRON', 'PROPN', 'ADP', 'NOUN', 'VERB', 'VERB', 'AUX', 'AUX']\n"
     ]
    }
   ],
   "source": [
    "from codemixtoolkit.models import PoSTagger\n",
    "\n",
    "postagger = PoSTagger(model_path=\"prakod/en-hi-pos-tagger-symcom\", \n",
    "                      tokenizer_path=\"xlm-roberta-base\")\n",
    "postagger.load_model_tokenizer()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "predicted_pos_tags = postagger.predict_pos_sentence(sentence)\n",
    "print(\"Predicted POS tags:\", predicted_pos_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a085cd",
   "metadata": {},
   "source": [
    "# Normalisation / Romanisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16610bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashantk/miniconda3/envs/codemixtoolkit/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "Loading dicts into RAM: 100%|██████████| 1/1 [00:00<00:00, 23.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'main hyderabaed main movie dekhane jaa rahaa hoon'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codemixtoolkit.models import Romanizer\n",
    "romanizer = Romanizer()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "romanizer.romanize_text(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584614b3",
   "metadata": {},
   "source": [
    "# Unicode Based LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a3af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LID tags: (['मैं', 'Hyderabaed', 'में', 'movie', 'देखने', 'जा', 'रहा', 'हूँ'], ['hi', 'ne', 'hi', 'en', 'hi', 'hi', 'hi', 'hi'])\n"
     ]
    }
   ],
   "source": [
    "from codemixtoolkit.models import UnicodeLIDtagger\n",
    "\n",
    "lid_tagger = UnicodeLIDtagger()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "ner_predictions = [False, 'ne', False, False, False, False, False, False]\n",
    "lid_tags = lid_tagger.get_unicode_lid_predictions(sentence,\n",
    "                                      ner_predictions = ner_predictions)\n",
    "print(\"LID tags:\", lid_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdea764",
   "metadata": {},
   "source": [
    "# LID Tagger and Normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a0ef0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "CSNLI Service is available?: False\n",
      "--------------------------------\n",
      "CSNLI Service is not available. Please check the service is running and the base_url is correct.\n"
     ]
    }
   ],
   "source": [
    "from codemixtoolkit.models import CSNLILIDClient\n",
    "\n",
    "# Initialize the client (defaults to http://localhost:6000)\n",
    "client = CSNLILIDClient(base_url = \"http://localhost:6000\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(f\"CSNLI Service is available?: {client.is_service_available()}\")\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "from pprint import pprint\n",
    "# Check if service is available\n",
    "if client.is_service_available():\n",
    "    # Process text and get results as a dictionary\n",
    "    result = client.get_lid(\"i thght mosam dfrnt hoga bs fog h\")\n",
    "    pprint(\"CSNLI API Result: \")\n",
    "    print(f\"Sentence: {result['text_str']}\")\n",
    "    print(f\"Tokenized: {result['text_tokenized']}\")\n",
    "    print(f\"Normalized: {result['norm_text']}\")\n",
    "    print(f\"LID: {result['lid']}\")\n",
    "    print(\"--------------------------------\")\n",
    "    \n",
    "else:\n",
    "    print(\"CSNLI Service is not available. Please check the service is running and the base_url is correct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b86bdda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSNLI Service is not available. Please check the service is running and the base_url is correct.\n"
     ]
    }
   ],
   "source": [
    "# Check if service is available\n",
    "if client.is_service_available():\n",
    "    # Process text and print results as a pandas DataFrame\n",
    "    print(\"--------------------------------\")\n",
    "    df = client.get_lid_and_print(\"i thght mosam dfrnt hoga bs fog h\")\n",
    "    print(f\"CSNLI API Result as DataFrame: \\n{df}\")\n",
    "    print(\"--------------------------------\")\n",
    "else:\n",
    "    print(\"CSNLI Service is not available. Please check the service is running and the base_url is correct.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9affb006",
   "metadata": {},
   "source": [
    "# Rule Based Synthetic Code-Mixed Sentence Generation - NOUN, ADJ Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44a681db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b15d62ce9b48f3b8fc4d26c0d83a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "INFO:stanza:Downloading default packages for language: en (English) ...\n",
      "INFO:stanza:File exists: /home/prashantk/stanza_resources/en/default.zip\n",
      "INFO:stanza:Finished downloading models and saved to /home/prashantk/stanza_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dabd62aebf04f3e96b628355d2965f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "INFO:stanza:Downloading default packages for language: hi (Hindi) ...\n",
      "INFO:stanza:File exists: /home/prashantk/stanza_resources/hi/default.zip\n",
      "INFO:stanza:Finished downloading models and saved to /home/prashantk/stanza_resources\n",
      "0it [00:00, ?it/s]INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd04377cedab4030b9a267a4d1ccd6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "WARNING:stanza:Language en package default expects mwt, which has been added\n",
      "INFO:stanza:Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "INFO:stanza:Using device: cuda\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: mwt\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Done loading processors!\n",
      "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a97477359c2479da7cfd2d3fff7352d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "INFO:stanza:Loading these models for language: hi (Hindi):\n",
      "===========================\n",
      "| Processor | Package     |\n",
      "---------------------------\n",
      "| tokenize  | hdtb        |\n",
      "| pos       | hdtb_charlm |\n",
      "===========================\n",
      "\n",
      "INFO:stanza:Using device: cuda\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Done loading processors!\n",
      "1it [00:03,  3.74s/it]\n",
      "1it [00:00, 22.29it/s]\n",
      "1it [00:00, 5857.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>hi</th>\n",
       "      <th>lang1</th>\n",
       "      <th>lang1_tokens</th>\n",
       "      <th>lang1_pos</th>\n",
       "      <th>lang2</th>\n",
       "      <th>lang2_tokens</th>\n",
       "      <th>lang2_pos</th>\n",
       "      <th>alignments_awesomealign</th>\n",
       "      <th>token_alignment_map_awesomealign</th>\n",
       "      <th>codemixed-sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay, how much does it cost?</td>\n",
       "      <td>ठीक है, इसकी लागत कितनी है?</td>\n",
       "      <td>en</td>\n",
       "      <td>[[Okay, ,, how, much, does, it, cost, ?]]</td>\n",
       "      <td>[[INTJ, PUNCT, ADV, ADV, AUX, PRON, VERB, PUNCT]]</td>\n",
       "      <td>hi</td>\n",
       "      <td>[[ठीक, है, ,, इसकी, लागत, कितनी, है, ?]]</td>\n",
       "      <td>[[ADJ, AUX, PUNCT, PRON, NOUN, DET, AUX, PUNCT]]</td>\n",
       "      <td>[0-0 0-1 1-2 2-5 3-4 4-6 5-3 6-4 7-7 ]</td>\n",
       "      <td>[{'Okay': 'है', 'ठीक': 'Okay', 'है': 'does', '...</td>\n",
       "      <td>Okay है , इसकी cost कितनी है ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             en                           hi lang1  \\\n",
       "0  Okay, how much does it cost?  ठीक है, इसकी लागत कितनी है?    en   \n",
       "\n",
       "                                lang1_tokens  \\\n",
       "0  [[Okay, ,, how, much, does, it, cost, ?]]   \n",
       "\n",
       "                                           lang1_pos lang2  \\\n",
       "0  [[INTJ, PUNCT, ADV, ADV, AUX, PRON, VERB, PUNCT]]    hi   \n",
       "\n",
       "                               lang2_tokens  \\\n",
       "0  [[ठीक, है, ,, इसकी, लागत, कितनी, है, ?]]   \n",
       "\n",
       "                                          lang2_pos  \\\n",
       "0  [[ADJ, AUX, PUNCT, PRON, NOUN, DET, AUX, PUNCT]]   \n",
       "\n",
       "                  alignments_awesomealign  \\\n",
       "0  [0-0 0-1 1-2 2-5 3-4 4-6 5-3 6-4 7-7 ]   \n",
       "\n",
       "                    token_alignment_map_awesomealign  \\\n",
       "0  [{'Okay': 'है', 'ठीक': 'Okay', 'है': 'does', '...   \n",
       "\n",
       "               codemixed-sentences  \n",
       "0   Okay है , इसकी cost कितनी है ?  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codemixtoolkit import tokenize_pos_awesome_align as tpa\n",
    "\n",
    "filename = \"unique_utterances_en_hi_transltions.json\"\n",
    "df_codemixed = tpa.get_codemix_candidates_for_file(filename)\n",
    "df_codemixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d63ae",
   "metadata": {},
   "source": [
    "# Synthetic Code-Mix Sentences Generated - GCM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594181a",
   "metadata": {},
   "source": [
    "- Ensure you are in the \"library\" folder\n",
    "\n",
    "- Run these commands:\n",
    " ```\n",
    " >>> export FLASK_APP=gcmgenerator\n",
    " >>> flask run -h 0.0.0.0 -p 6000\n",
    " ```\n",
    "- (change port and host details as required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0daf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "\n",
    "def is_image_running(image_name=\"prakod/gcm-codemix-generator\"):\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    # List all running containers\n",
    "    running_containers = client.containers.list()\n",
    "    \n",
    "    for container in running_containers:\n",
    "        # Check if the container is using the specified image\n",
    "        if container.image.tags and image_name in container.image.tags[0]:\n",
    "            return True\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c213d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is running.\n"
     ]
    }
   ],
   "source": [
    "if is_image_running(image_name=\"prakod/gcm-codemix-generator\"):\n",
    "    print(\"The image is running.\")\n",
    "else:\n",
    "    print(\"The image is not running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23603127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check APIs are reachable\n",
    "\n",
    "import requests\n",
    "\n",
    "def check_api_reachable(url, method='GET', timeout=5, payload=None):\n",
    "    \"\"\"\n",
    "    Checks if the given API endpoint is reachable.\n",
    "    Args:\n",
    "        url (str): The API endpoint URL.\n",
    "        method (str): HTTP method to use ('GET' or 'POST').\n",
    "        timeout (int): Timeout in seconds for the request.\n",
    "        payload (dict): Data to send in case of POST.\n",
    "    Returns:\n",
    "        bool: True if reachable, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method.upper() == 'POST':\n",
    "            response = requests.post(url, json=payload, timeout=timeout)\n",
    "        else:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"API returned status code: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API is not available: {e}\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c30ac",
   "metadata": {},
   "source": [
    "## ALIGNER\n",
    "\n",
    "- Sentences are passed here, and the alignment is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf971e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'alignment': '0-4 1-5 2-3 3-2 4-0 5-0', 'l1': 'यदि आप तुरंत डॉक्टर से संपर्क करें', 'l2': 'contact the doctor immediately if you'}\n"
     ]
    }
   ],
   "source": [
    "# alignment generation\n",
    "l1 = \"यदि आप तुरंत डॉक्टर से संपर्क करें\"\n",
    "l2 = \"contact the doctor immediately if you\"\n",
    "td = {'l1':l1, 'l2':l2}\n",
    "alignment_api_endpoint = \"http://127.0.0.1:6000/statistical_aligner_enhi\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'alignment': '0-4 1-5 2-3 3-2 4-0 5-0', 'l1': 'यदि आप तुरंत डॉक्टर से संपर्क करें', 'l2': 'contact the doctor immediately if you'}\n"
     ]
    }
   ],
   "source": [
    "# alignment generation\n",
    "l1 = \"यदि आप तुरंत डॉक्टर से संपर्क करें\"\n",
    "l2 = \"contact the doctor immediately if you\"\n",
    "td = {'l1':l1, 'l2':l2}\n",
    "alignment_api_endpoint = \"http://127.0.0.1:6000/statistical_aligner_enhi\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d68533",
   "metadata": {},
   "source": [
    "## CODE-MIXED SENTENCE GENERATOR\n",
    "\n",
    "- Using the given sentences and alignment, codemixed sentences are generated\n",
    "\n",
    "### Expected Outputs\n",
    "\n",
    "- In case of any error during code-mix sentence generation, the program errors out with the message: \n",
    "```\n",
    "fail\n",
    "```\n",
    "\n",
    "- Sometimes it is possible that no alignments can be generated, in which case the program returns an empty array.\n",
    "- If any alignment error occurs then it is possible for the code-mixed sentence to skip a few words as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm-sentences generation\n",
    "choice = 2  #choice for language to generate parse trees\n",
    "data = {\n",
    "    \"lang1\": l1,\n",
    "    \"lang2\": l2,\n",
    "    \"alignments\": alignments,\n",
    "    \"choice\": choice\n",
    "}\n",
    "\n",
    "gcm_api_endpoint = \"http://127.0.0.1:6000/gcm_enhi\"\n",
    "#CODE FOUND IN gcmgenerator.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gcm_enhi API is reachable.\n"
     ]
    }
   ],
   "source": [
    "# check if the gcm_enhi API is reachable\n",
    "if not check_api_reachable(\"http://127.0.0.1:6000/gcm_enhi\", method='POST', payload=data, timeout=60):\n",
    "    print(\"The gcm_enhi API is not available.\")\n",
    "else:\n",
    "    print(\"The gcm_enhi API is reachable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Sentence 1:  यदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "Sentence 2:  contact the doctor immediately if you\n",
      "Alignments:  ['0-4 1-5 2-3 3-2 4-0 5-0']\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]contact the तुरंत if you\n",
      "\n",
      "[TREE](ROOT (VP_e (VB_e contact) (NP_e (DT_e the)) (ADVP (RB_h तुरंत)) (SBAR (IN_e if) (NP (PRP_e you)))))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]contact the तुरंत if आप\n",
      "\n",
      "[TREE](ROOT (VP_e (VB_e contact) (NP_e (DT_e the)) (ADVP (RB_h तुरंत)) (SBAR (IN_e if) (NP (PRP_h आप)))))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]if आप immediately डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_e if) (NP (PRP_h आप))) (ADVP (RB_e immediately)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]if आप तुरंत doctor से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_e if) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_e doctor)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]if आप तुरंत डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_e if) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि you तुरंत doctor से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_e you))) (ADVP (RB_h तुरंत)) (NP_h (NN_e doctor)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि you तुरंत डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_e you))) (ADVP (RB_h तुरंत)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि आप immediately डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_h आप))) (ADVP (RB_e immediately)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि आप तुरंत doctor से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_e doctor)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि आप तुरंत डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(gcm_api_endpoint, json=data)\n",
    "print(response)\n",
    "#print(response.json())\n",
    "\n",
    "retdata = response.json()\n",
    "print(\"Sentence 1: \", retdata['lang1'])\n",
    "print(\"Sentence 2: \", retdata['lang2'])\n",
    "print(\"Alignments: \", retdata['alignments'])\n",
    "for i in retdata['cm_sentences']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f630a7",
   "metadata": {},
   "source": [
    "# Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb236a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codemixtoolkit.data import (\n",
    "    DATASET_REGISTRY,\n",
    "    LanguagePair,\n",
    "    TaskType,\n",
    "    DatasetInfo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c3e9f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      "['AcceptabilityEnHiClineGCM', 'AcceptabilityEnHiClineOSN', 'ToDDialogXRISAWOZ', 'SentimentEnHiPrabhuEtAl', 'SentimentEnHiGLUECOS', 'SentimentEnHiSentiMix', 'HateSpeechEnHiBohraEtAl']\n"
     ]
    }
   ],
   "source": [
    "# 1. List all available datasets\n",
    "print(\"Available datasets:\")\n",
    "print(DATASET_REGISTRY.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3565b52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets for sequence classification:\n",
      "['ToDDialogXRISAWOZ', 'SentimentEnHiPrabhuEtAl', 'SentimentEnHiGLUECOS', 'SentimentEnHiSentiMix', 'HateSpeechEnHiBohraEtAl']\n"
     ]
    }
   ],
   "source": [
    "# 2. List datasets by task type\n",
    "print(\"\\nDatasets for sequence classification:\")\n",
    "print(DATASET_REGISTRY.list_datasets_by_task(TaskType.SEQUENCE_CLASSIFICATION))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72830e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets for English-Hindi:\n",
      "-----------DATASET REGISTRY - START---------------------\n",
      "AcceptabilityEnHiClineGCM\n",
      "AcceptabilityEnHiClineOSN\n",
      "ToDDialogXRISAWOZ\n",
      "SentimentEnHiPrabhuEtAl\n",
      "SentimentEnHiGLUECOS\n",
      "SentimentEnHiSentiMix\n",
      "HateSpeechEnHiBohraEtAl\n",
      "-----------DATASET REGISTRY - END---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. List datasets by language pair\n",
    "print(\"\\nDatasets for English-Hindi:\")\n",
    "print(DATASET_REGISTRY.list_datasets_by_languagepair(LanguagePair.EN_HI))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91a63e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since prakod/hate_speech_enhi_bohraetal couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since prakod/hate_speech_enhi_bohraetal couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/prashantk/.cache/huggingface/datasets/prakod___hate_speech_enhi_bohraetal/default/0.0.0/84d0496a1b0c26faa15fb6f93e4ae697fa488438 (last modified on Wed Feb 12 19:34:01 2025).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'default' at /home/prashantk/.cache/huggingface/datasets/prakod___hate_speech_enhi_bohraetal/default/0.0.0/84d0496a1b0c26faa15fb6f93e4ae697fa488438 (last modified on Wed Feb 12 19:34:01 2025).\n"
     ]
    }
   ],
   "source": [
    "# 4. Load a specific dataset\n",
    "# Example: Loading the Sentiment dataset from Prabhu et al.\n",
    "sentiment_dataset = DATASET_REGISTRY.get_dataset(\"HateSpeechEnHiBohraEtAl\")\n",
    "data = sentiment_dataset.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77197011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Information:\n",
      "Name: hate-speech-en-hi-bohra-et-al\n",
      "Task Type: TaskType.SEQUENCE_CLASSIFICATION\n",
      "Language Pair: LanguagePair.EN_HI\n",
      "Input Fields: ['text']\n",
      "Label Fields: ['label']\n",
      "Metrics: ['accuracy']\n",
      "Description: Hate Speech Dataset - En-Hi - Bohra et al.\n",
      "Reference: https://arxiv.org/abs/2405.05572\n"
     ]
    }
   ],
   "source": [
    "# 5. Get dataset information\n",
    "dataset_info = sentiment_dataset.get_info()\n",
    "print(\"\\nDataset Information:\")\n",
    "print(f\"Name: {dataset_info.name}\")\n",
    "print(f\"Task Type: {dataset_info.task_type}\")\n",
    "print(f\"Language Pair: {dataset_info.language_pair}\")\n",
    "print(f\"Input Fields: {dataset_info.input_fields}\")\n",
    "print(f\"Label Fields: {dataset_info.label_fields}\")\n",
    "print(f\"Metrics: {dataset_info.metrics}\")\n",
    "print(f\"Description: {dataset_info.description}\")\n",
    "print(f\"Reference: {dataset_info.reference}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24cb742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data from sentiment dataset:\n",
      "{'text': 'Ek CM Gaaye Ki Seva Mai laga hua hai, aur baaki 3 CM #Padmavaat ko ban kraane Mai lage hue. Sabse jaada beshram, Haryana CM, Jo har Baar mauka deta hai sabko, kuch na kuch bolne pr, chaiye voh Ram Rahim ho, Brutal Rape ho ya Padmavati ho. I hate these 4 CMs of @BJP4India #Useless', 'label': 0, 'label_text': 'hate', 'label_id_str': 0}\n"
     ]
    }
   ],
   "source": [
    "# 6. Working with the loaded data\n",
    "# The data is returned as a HuggingFace Dataset object\n",
    "# You can access it like a pandas DataFrame\n",
    "print(\"\\nSample data from sentiment dataset:\")\n",
    "print(data['train'][0])  # Print first example from training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a5eed",
   "metadata": {},
   "source": [
    "# Evaluation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77933b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codemixtoolkit.evaluation import (\n",
    "    LLMEvaluator,\n",
    "    PerplexityEvaluator,\n",
    "    EvaluationMetrics\n",
    ")\n",
    "from codemixtoolkit.data import DATASET_REGISTRY\n",
    "\n",
    "from codemixtoolkit.config import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6e731d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since prakod/hate_speech_enhi_bohraetal couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since prakod/hate_speech_enhi_bohraetal couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/prashantk/.cache/huggingface/datasets/prakod___hate_speech_enhi_bohraetal/default/0.0.0/84d0496a1b0c26faa15fb6f93e4ae697fa488438 (last modified on Wed Feb 12 19:34:01 2025).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'default' at /home/prashantk/.cache/huggingface/datasets/prakod___hate_speech_enhi_bohraetal/default/0.0.0/84d0496a1b0c26faa15fb6f93e4ae697fa488438 (last modified on Wed Feb 12 19:34:01 2025).\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_obj = DATASET_REGISTRY.get_dataset(\"HateSpeechEnHiBohraEtAl\")\n",
    "\n",
    "# Load the dataset with HuggingFace token\n",
    "dataset_data = dataset_obj.load(token=config.HUGGINGFACE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15aaae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset label mapping: {'hate': 0, 'non-hate': 1}\n",
      "Instruction label mapping: {'hate_speech': 0, 'not_hate_speech': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define label mapping for the dataset\n",
    "\n",
    "dataset_label_mapping = {}\n",
    "for label in dataset_data[\"train\"].features[\"label\"].names:\n",
    "    dataset_label_mapping[label] = (\n",
    "        dataset_data[\"train\"].features[\"label\"].str2int(label)\n",
    "    )\n",
    "\n",
    "\n",
    "instruction_label_mapping = {\"hate_speech\": 0, \"not_hate_speech\": 1}\n",
    "\n",
    "print(f\"Dataset label mapping: {dataset_label_mapping}\")\n",
    "print(f\"Instruction label mapping: {instruction_label_mapping}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c72a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------- \n",
      "\n",
      "Sample text: Ek CM Gaaye Ki Seva Mai laga hua hai, aur baaki 3 CM #Padmavaat ko ban kraane Mai lage hue. Sabse jaada beshram, Haryana CM, Jo har Baar mauka deta hai sabko, kuch na kuch bolne pr, chaiye voh Ram Rahim ho, Brutal Rape ho ya Padmavati ho. I hate these 4 CMs of @BJP4India #Useless\n",
      "True label: 0\n",
      "Label as string: hate\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Select a sample from the dataset\n",
    "sample = dataset_data[\"train\"][0]\n",
    "print(\"-------------------------------- \")\n",
    "print(\"\\nSample text:\", sample[\"text\"])\n",
    "print(f\"True label: {sample['label']}\")\n",
    "print(f\"Label as string: {sample['label_text']}\")\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73ee750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LLM-based Evaluation Example\n",
    "# Initialize LLM evaluator for sentiment classification\n",
    "\n",
    "zero_shot_evaluator = LLMEvaluator(\n",
    "        tasktype=\"sequence_classification\",\n",
    "        task=\"hate_speech\",\n",
    "        name=\"zero_shot_hate_speech\",\n",
    "        model=\"openrouter/meta-llama/llama-3.3-70b-instruct:free\",\n",
    "        temperature=0.1,\n",
    "        max_tokens=10,\n",
    "        instruction=\"\"\"You are a hate speech classifier. Given a text, classify it as either 'hate speech' or 'not hate speech'.\n",
    "Hate speech is defined as any form of expression that attacks or uses pejorative or discriminatory language with reference to a person or a group on the basis of who they are, in other words, based on their religion, ethnicity, nationality, race, color, descent, gender or other identity factor.\n",
    "\n",
    "Respond with only one word: either 'hate_speech' or 'not_hate_speech'.\"\"\",\n",
    "        dataset_label_mapping=dataset_label_mapping,\n",
    "        instruction_label_mapping=instruction_label_mapping,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83dd5ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: hate_speech\n",
      "Prediction with label mapping: 0\n",
      "Correct Prediction! Prediction 0 matches ground truth 0\n"
     ]
    }
   ],
   "source": [
    "# Get predictions and compare with ground truth using both evaluators\n",
    "zero_shot_result = zero_shot_evaluator.evaluate_sample(\n",
    "    sample[\"text\"], sample[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71eabfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on 10 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset: 100%|██████████| 10/10 [00:16<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on 10 samples\n",
    "print(\"\\nEvaluating on 10 samples...\")\n",
    "dataset_eval_10 = zero_shot_evaluator.evaluate_dataset(\n",
    "    dataset_obj,\n",
    "    max_eval_samples=10,  # Limit to 10 samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f63193d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics:\n",
      "{'accuracy': 0.6, 'f1': 0.6380952380952382}\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Metrics:\")\n",
    "print(dataset_eval_10['metrics'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codemixtoolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
