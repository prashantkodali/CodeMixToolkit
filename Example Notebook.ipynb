{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314a3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66199363",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['Gully', 'cricket', 'चल', 'रहा', 'हैं', 'यहां', '\"', '(', 'Soniya', ')', 'Gandhi', '\"']\n",
    "LID_Tags = ['en', 'en', 'hi', 'hi', 'hi', 'hi', 'univ', 'univ', 'ne', 'univ', 'ne', 'univ']\n",
    "PoS_Tags = ['ADJ', 'PROPN', 'VERB', 'AUX', 'AUX', 'ADV', 'PUNCT', 'PUNCT', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT']\n",
    "\n",
    "lang_tags = ['hi', 'en']\n",
    "other_tags = ['univ', 'ne', 'acro']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79fd67",
   "metadata": {},
   "source": [
    "# CodeMixed Sentence Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9599d83",
   "metadata": {},
   "source": [
    "CodeMixSentence object serves as a comprehensive container for analyzing and quantifying code-mixing. It encapsulates \n",
    "- structural components of a sentence (tokens, language tags, part-of-speech tags) \n",
    "- various metrics that measure the degree and patterns of language mixing, such as Code-Mixing Index (CMI), burstiness, language entropy, and SyMCoM scores. \n",
    "\n",
    "The CodeMixSentence object provides a standardized framework for computing and storing code-mixing metrics, which is essential for several reasons:\n",
    "\n",
    "- Standardisation: Having a standardized format, capturing necessary attributes of a code-mixed sentence, makes it easier to share and compare results across different datasets, and across the research community.\n",
    "\n",
    "- Reproducibility & Consistency: By encapsulating all the metrics (CMI, burstiness, I-index, language entropy, etc.) in a single object with well-defined computation methods, it ensures that one can reproduce the same results when analyzing code-mixed text.\n",
    "\n",
    "- Extensibility: The object provides a clear structure for adding new metrics or modifying existing ones while maintaining compatibility with the established framework. This is important as the field of code-mixing research continues to evolve.\n",
    "\n",
    "\n",
    "The CodeMixSentence object provides a common ground for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ead67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codemix.cs_metrics import CodeMixSentence\n",
    "codemixed_sentence = CodeMixSentence(lang_tagset = lang_tags, \n",
    "                                    other_tagset = other_tags, \n",
    "                                    l1 = 'en', \n",
    "                                    l2 = 'hi', \n",
    "                                    sentence = None, \n",
    "                                    tokens = tokens, \n",
    "                                    LID_Tags = LID_Tags, \n",
    "                                    PoS_Tags = PoS_Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69dfb3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeMixSentenceCombined(\n",
      "    lang_tagset=['hi', 'en'],\n",
      "    other_tagset=['univ', 'ne', 'acro'],\n",
      "    l1='en',\n",
      "    l2='hi',\n",
      "    sentence='None',\n",
      "    tokens=['Gully', 'cricket', 'चल', 'रहा', 'हैं', 'यहां', '\"', '(', 'Soniya', ')', 'Gandhi', '\"'],\n",
      "    LID_Tags=['en', 'en', 'hi', 'hi', 'hi', 'hi'],\n",
      "    PoS_Tags=['ADJ', 'PROPN', 'VERB', 'AUX', 'AUX', 'ADV', 'PUNCT', 'PUNCT', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT'],\n",
      "    length=12,\n",
      "    cmi=None,\n",
      "    burstiness=None,\n",
      "    i_index=None,\n",
      "    lang_entropy=None,\n",
      "    mindex=None,\n",
      "    spavg=None,\n",
      "    symcom_sentence=None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(codemixed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8568788",
   "metadata": {},
   "source": [
    "# CodeMix Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4706e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeMixSentenceCombined(\n",
      "    lang_tagset=['hi', 'en'],\n",
      "    other_tagset=['univ', 'ne', 'acro'],\n",
      "    l1='en',\n",
      "    l2='hi',\n",
      "    sentence='None',\n",
      "    tokens=['Gully', 'cricket', 'चल', 'रहा', 'हैं', 'यहां', '\"', '(', 'Soniya', ')', 'Gandhi', '\"'],\n",
      "    LID_Tags=['en', 'en', 'hi', 'hi', 'hi', 'hi'],\n",
      "    PoS_Tags=['ADJ', 'PROPN', 'VERB', 'AUX', 'AUX', 'ADV', 'PUNCT', 'PUNCT', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT'],\n",
      "    length=12,\n",
      "    cmi=33.333333333333336,\n",
      "    burstiness=-0.3592455179659185,\n",
      "    i_index=0.2,\n",
      "    lang_entropy=0.9182958340544896,\n",
      "    mindex=0.7999999999999999,\n",
      "    spavg=1,\n",
      "    symcom_sentence=0.6666666666666666\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Computes all the metrics for the code-mixed sentence object which would have necessary fields like LID Tags and PoS Tags.\n",
    "'''\n",
    "\n",
    "codemixed_sentence.compute_all_metrics()\n",
    "print(codemixed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a21ba",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8c9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codemix import codemix_viz as cv\n",
    "\n",
    "annotation_printer = cv.AnnotatedTextPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40706eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#1f77b4;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">Gully<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">ADJ</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#1f77b4;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">cricket<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PROPN</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">चल<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">VERB</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">रहा<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">AUX</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">हैं<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">AUX</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#D55E00;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">यहां<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">ADV</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">&quot;<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">(<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#7f7f7f;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">Soniya<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PROPN</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">)<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#7f7f7f;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">Gandhi<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PROPN</span></span><span style=\"display:inline-flex;flex-direction:row;align-items:center;background:#17becf;border-radius:0.5rem;padding:0.25rem 0.5rem;overflow:hidden;line-height:1\">&quot;<span style=\"border-left:1px solid;opacity:0.1;margin-left:0.5rem;align-self:stretch\"></span><span style=\"margin-left:0.5rem;font-size:0.75rem;opacity:0.5\">PUNCT</span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_printer.print_sample_st_annot_text(tokens, LID_Tags, PoS_Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b63669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file saved as codemix_visualization_test.html\n"
     ]
    }
   ],
   "source": [
    "annotation_printer.export_html(file_name=\"codemix_visualization_test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3445ad",
   "metadata": {},
   "source": [
    "# NER Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8dc2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashantk/miniconda3/envs/codemixtoolkit/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False, 'ne', False, False, False, False, False, False]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codemix.compute import NERtagger\n",
    "\n",
    "ner_tagger = NERtagger(model_path=\"ai4bharat/IndicNER\", \n",
    "                       tokenizer_path=\"ai4bharat/IndicNER\")\n",
    "ner_tagger.load_model_tokenizer()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "predicted_ner_tags = ner_tagger.predict_ner_sentence(sentence)\n",
    "predicted_ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360871a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = NERtagger(model_path=\"ai4bharat/IndicNER\", \n",
    "                       tokenizer_path=\"ai4bharat/IndicNER\",\n",
    "                       finegrain_labels=True)\n",
    "ner_tagger.load_model_tokenizer()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "predicted_ner_tags = ner_tagger.predict_ner_sentence(sentence)\n",
    "predicted_ner_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec06275",
   "metadata": {},
   "source": [
    "# PoS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3f78b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted POS tags: ['PRON', 'PROPN', 'ADP', 'NOUN', 'VERB', 'VERB', 'AUX', 'AUX']\n"
     ]
    }
   ],
   "source": [
    "from codemix.compute import PoSTagger\n",
    "\n",
    "postagger = PoSTagger(model_path=\"prakod/en-hi-pos-tagger-symcom\", \n",
    "                      tokenizer_path=\"xlm-roberta-base\")\n",
    "postagger.load_model_tokenizer()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "predicted_pos_tags = postagger.predict_pos_sentence(sentence)\n",
    "print(\"Predicted POS tags:\", predicted_pos_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584614b3",
   "metadata": {},
   "source": [
    "# Unicode Based LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f900d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LID tags: (['मैं', 'Hyderabaed', 'में', 'movie', 'देखने', 'जा', 'रहा', 'हूँ'], ['hi', 'ne', 'hi', 'en', 'hi', 'hi', 'hi', 'hi'])\n"
     ]
    }
   ],
   "source": [
    "from codemix.compute import UnicodeLIDtagger\n",
    "\n",
    "lid_tagger = UnicodeLIDtagger()\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "ner_predictions = [False, 'ne', False, False, False, False, False, False]\n",
    "lid_tags = lid_tagger.get_unicode_lid_predictions(sentence,\n",
    "                                      ner_predictions = ner_predictions)\n",
    "print(\"LID tags:\", lid_tags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a085cd",
   "metadata": {},
   "source": [
    "# Normalisation / Romanisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d94d57b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashantk/miniconda3/envs/codemixtoolkit/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "Loading dicts into RAM: 100%|██████████| 1/1 [00:00<00:00, 18.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'main hyderabaed main movie dekhane jaa rahaa hoon'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codemix.normalize import Normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "sentence = \"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "normalizer.normalize_text(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9affb006",
   "metadata": {},
   "source": [
    "# Rule Based Synthetic Code-Mixed Sentence Generation - NOUN, ADJ Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a681db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 23.1MB/s]                    \n",
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "INFO:stanza:Downloading default packages for language: en (English) ...\n",
      "INFO:stanza:File exists: /home/prashantk/stanza_resources/en/default.zip\n",
      "INFO:stanza:Finished downloading models and saved to /home/prashantk/stanza_resources\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 24.0MB/s]                    \n",
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "INFO:stanza:Downloading default packages for language: hi (Hindi) ...\n",
      "INFO:stanza:File exists: /home/prashantk/stanza_resources/hi/default.zip\n",
      "INFO:stanza:Finished downloading models and saved to /home/prashantk/stanza_resources\n",
      "0it [00:00, ?it/s]INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 22.9MB/s]                    \n",
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "WARNING:stanza:Language en package default expects mwt, which has been added\n",
      "INFO:stanza:Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "INFO:stanza:Using device: cuda\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: mwt\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Done loading processors!\n",
      "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 18.8MB/s]                    \n",
      "INFO:stanza:Downloaded file to /home/prashantk/stanza_resources/resources.json\n",
      "INFO:stanza:Loading these models for language: hi (Hindi):\n",
      "===========================\n",
      "| Processor | Package     |\n",
      "---------------------------\n",
      "| tokenize  | hdtb        |\n",
      "| pos       | hdtb_charlm |\n",
      "===========================\n",
      "\n",
      "INFO:stanza:Using device: cuda\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Done loading processors!\n",
      "1it [00:03,  3.70s/it]\n",
      "1it [00:00,  3.78it/s]\n",
      "1it [00:00, 5289.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>hi</th>\n",
       "      <th>lang1</th>\n",
       "      <th>lang1_tokens</th>\n",
       "      <th>lang1_pos</th>\n",
       "      <th>lang2</th>\n",
       "      <th>lang2_tokens</th>\n",
       "      <th>lang2_pos</th>\n",
       "      <th>alignments_awesomealign</th>\n",
       "      <th>token_alignment_map_awesomealign</th>\n",
       "      <th>codemixed-sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay, how much does it cost?</td>\n",
       "      <td>ठीक है, इसकी लागत कितनी है?</td>\n",
       "      <td>en</td>\n",
       "      <td>[[Okay, ,, how, much, does, it, cost, ?]]</td>\n",
       "      <td>[[INTJ, PUNCT, ADV, ADV, AUX, PRON, VERB, PUNCT]]</td>\n",
       "      <td>hi</td>\n",
       "      <td>[[ठीक, है, ,, इसकी, लागत, कितनी, है, ?]]</td>\n",
       "      <td>[[ADJ, AUX, PUNCT, PRON, NOUN, DET, AUX, PUNCT]]</td>\n",
       "      <td>[0-0 0-1 1-2 2-5 3-4 4-6 5-3 6-4 7-7 ]</td>\n",
       "      <td>[{'Okay': 'है', 'ठीक': 'Okay', 'है': 'does', '...</td>\n",
       "      <td>Okay है , इसकी cost कितनी है ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             en                           hi lang1  \\\n",
       "0  Okay, how much does it cost?  ठीक है, इसकी लागत कितनी है?    en   \n",
       "\n",
       "                                lang1_tokens  \\\n",
       "0  [[Okay, ,, how, much, does, it, cost, ?]]   \n",
       "\n",
       "                                           lang1_pos lang2  \\\n",
       "0  [[INTJ, PUNCT, ADV, ADV, AUX, PRON, VERB, PUNCT]]    hi   \n",
       "\n",
       "                               lang2_tokens  \\\n",
       "0  [[ठीक, है, ,, इसकी, लागत, कितनी, है, ?]]   \n",
       "\n",
       "                                          lang2_pos  \\\n",
       "0  [[ADJ, AUX, PUNCT, PRON, NOUN, DET, AUX, PUNCT]]   \n",
       "\n",
       "                  alignments_awesomealign  \\\n",
       "0  [0-0 0-1 1-2 2-5 3-4 4-6 5-3 6-4 7-7 ]   \n",
       "\n",
       "                    token_alignment_map_awesomealign  \\\n",
       "0  [{'Okay': 'है', 'ठीक': 'Okay', 'है': 'does', '...   \n",
       "\n",
       "               codemixed-sentences  \n",
       "0   Okay है , इसकी cost कितनी है ?  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codemix import tokenize_pos_awesome_align as tpa\n",
    "\n",
    "filename = \"unique_utterances_en_hi_transltions.json\"\n",
    "df_codemixed = tpa.get_codemix_candidates_for_file(filename)\n",
    "df_codemixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdea764",
   "metadata": {},
   "source": [
    "# LID Tagger and Normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d7a8f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: i thght mosam dfrnt hoga bs fog h\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>lid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thght</td>\n",
       "      <td>thought</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mosam</td>\n",
       "      <td>मौसम</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dfrnt</td>\n",
       "      <td>different</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hoga</td>\n",
       "      <td>होगा</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bs</td>\n",
       "      <td>बस</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fog</td>\n",
       "      <td>fog</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>है</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_tokenized  norm_text lid\n",
       "0              i          i  en\n",
       "1          thght    thought  en\n",
       "2          mosam       मौसम  hi\n",
       "3          dfrnt  different  en\n",
       "4           hoga       होगा  hi\n",
       "5             bs         बस  hi\n",
       "6            fog        fog  en\n",
       "7              h         है  hi"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:6000/csnli-lid\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\"text\": \"i thght mosam dfrnt hoga bs fog h\"}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "csnli_output = response.json()['csnli_op']\n",
    "\n",
    "print(f\"Sentence: {csnli_output['text_str']}\")\n",
    "\n",
    "#convert csnli_output to a pandas dataframe and print it and do not keep \"text_str\" in the dataframe \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(csnli_output)\n",
    "df = df.drop(columns=['text_str'])\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e3283",
   "metadata": {},
   "source": [
    "# Synthetic Code-Mixed Sentence Generation using GCM Toolkit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd09c07",
   "metadata": {},
   "source": [
    "## Instructions to run the flask API: \n",
    "\n",
    "- Ensure you are in the \"library\" folder\n",
    "\n",
    "- Run these commands:\n",
    " ```\n",
    " >>> export FLASK_APP=gcmgenerator\n",
    " >>> flask run -h 0.0.0.0 -p 6000\n",
    " ```\n",
    "- (change port and host details as required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59044dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "\n",
    "def is_image_running(image_name=\"prakod/gcm-codemix-generator\"):\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    # List all running containers\n",
    "    running_containers = client.containers.list()\n",
    "    \n",
    "    for container in running_containers:\n",
    "        # Check if the container is using the specified image\n",
    "        if container.image.tags and image_name in container.image.tags[0]:\n",
    "            return True\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is running.\n"
     ]
    }
   ],
   "source": [
    "if is_image_running(image_name=\"prakod/gcm-codemix-generator\"):\n",
    "    print(\"The image is running.\")\n",
    "else:\n",
    "    print(\"The image is not running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check APIs are reachable\n",
    "\n",
    "import requests\n",
    "\n",
    "def check_api_reachable(url, method='GET', timeout=5, payload=None):\n",
    "    \"\"\"\n",
    "    Checks if the given API endpoint is reachable.\n",
    "    Args:\n",
    "        url (str): The API endpoint URL.\n",
    "        method (str): HTTP method to use ('GET' or 'POST').\n",
    "        timeout (int): Timeout in seconds for the request.\n",
    "        payload (dict): Data to send in case of POST.\n",
    "    Returns:\n",
    "        bool: True if reachable, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method.upper() == 'POST':\n",
    "            response = requests.post(url, json=payload, timeout=timeout)\n",
    "        else:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"API returned status code: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API is not available: {e}\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4210bec",
   "metadata": {},
   "source": [
    "## ALIGNER\n",
    "\n",
    "- Sentences are passed here, and the alignment is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'alignment': '0-4 1-5 2-3 3-2 4-0 5-0', 'l1': 'यदि आप तुरंत डॉक्टर से संपर्क करें', 'l2': 'contact the doctor immediately if you'}\n"
     ]
    }
   ],
   "source": [
    "# alignment generation\n",
    "l1 = \"यदि आप तुरंत डॉक्टर से संपर्क करें\"\n",
    "l2 = \"contact the doctor immediately if you\"\n",
    "td = {'l1':l1, 'l2':l2}\n",
    "alignment_api_endpoint = \"http://127.0.0.1:6000/statistical_aligner_enhi\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_api_reachable(\"http://127.0.0.1:6000/statistical_aligner_enhi\", method='POST', payload={'l1': 'test', 'l2': 'test'}):\n",
    "    print(\"The statistical_aligner_enhi API is not available.\")\n",
    "else:\n",
    "    print(\"The statistical_aligner_enhi API is reachable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa29d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(alignment_api_endpoint, json = td)\n",
    "\n",
    "print(response)\n",
    "\n",
    "print(response.json())\n",
    "\n",
    "aligner_output = response.json()\n",
    "alignments = aligner_output['alignment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d68533",
   "metadata": {},
   "source": [
    "## CODE-MIXED SENTENCE GENERATOR\n",
    "\n",
    "- Using the given sentences and alignment, codemixed sentences are generated\n",
    "\n",
    "### Expected Outputs\n",
    "\n",
    "- In case of any error during code-mix sentence generation, the program errors out with the message: \n",
    "```\n",
    "fail\n",
    "```\n",
    "\n",
    "- Sometimes it is possible that no alignments can be generated, in which case the program returns an empty array.\n",
    "- If any alignment error occurs then it is possible for the code-mixed sentence to skip a few words as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm-sentences generation\n",
    "choice = 2  #choice for language to generate parse trees\n",
    "data = {\n",
    "    \"lang1\": l1,\n",
    "    \"lang2\": l2,\n",
    "    \"alignments\": alignments,\n",
    "    \"choice\": choice\n",
    "}\n",
    "\n",
    "gcm_api_endpoint = \"http://127.0.0.1:6000/gcm_enhi\"\n",
    "#CODE FOUND IN gcmgenerator.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gcm_enhi API is reachable.\n"
     ]
    }
   ],
   "source": [
    "# check if the gcm_enhi API is reachable\n",
    "if not check_api_reachable(\"http://127.0.0.1:6000/gcm_enhi\", method='POST', payload=data, timeout=60):\n",
    "    print(\"The gcm_enhi API is not available.\")\n",
    "else:\n",
    "    print(\"The gcm_enhi API is reachable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Sentence 1:  यदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "Sentence 2:  contact the doctor immediately if you\n",
      "Alignments:  ['0-4 1-5 2-3 3-2 4-0 5-0']\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]contact the तुरंत if you\n",
      "\n",
      "[TREE](ROOT (VP_e (VB_e contact) (NP_e (DT_e the)) (ADVP (RB_h तुरंत)) (SBAR (IN_e if) (NP (PRP_e you)))))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]contact the तुरंत if आप\n",
      "\n",
      "[TREE](ROOT (VP_e (VB_e contact) (NP_e (DT_e the)) (ADVP (RB_h तुरंत)) (SBAR (IN_e if) (NP (PRP_h आप)))))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]if आप immediately डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_e if) (NP (PRP_h आप))) (ADVP (RB_e immediately)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]if आप तुरंत doctor से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_e if) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_e doctor)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]if आप तुरंत डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_e if) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि you तुरंत doctor से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_e you))) (ADVP (RB_h तुरंत)) (NP_h (NN_e doctor)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि you तुरंत डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_e you))) (ADVP (RB_h तुरंत)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि आप immediately डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_h आप))) (ADVP (RB_e immediately)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि आप तुरंत doctor से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_e doctor)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n",
      "[IDX]\t0\n",
      "\n",
      "[L1]\tयदि आप तुरंत डॉक्टर से संपर्क करें\n",
      "\n",
      "[L2]\tcontact the doctor immediately if you\n",
      "\n",
      "[L2_Tree]\t(ROOT (S (VP (VB contact) (NP (DT the) (NN doctor)) (ADVP (RB immediately)) (SBAR (IN if) (NP (PRP you))))))\n",
      "\n",
      "Alignments\t0-4 1-5 2-3 3-2 4-0 5-0\n",
      "\n",
      "Theory\tec\n",
      "\n",
      "[CM]यदि आप तुरंत डॉक्टर से संपर्क\n",
      "\n",
      "[TREE](ROOT (VP_h (SBAR (IN_h यदि) (NP (PRP_h आप))) (ADVP (RB_h तुरंत)) (NP_h (NN_h डॉक्टर)) (VB_h से संपर्क)))\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(gcm_api_endpoint, json=data)\n",
    "print(response)\n",
    "#print(response.json())\n",
    "\n",
    "retdata = response.json()\n",
    "print(\"Sentence 1: \", retdata['lang1'])\n",
    "print(\"Sentence 2: \", retdata['lang2'])\n",
    "print(\"Alignments: \", retdata['alignments'])\n",
    "for i in retdata['cm_sentences']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e658ce58",
   "metadata": {},
   "source": [
    "# OLD / Prototype/ Testing - Delete Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2041d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cs_metrics.CodeMixMetrics(lang_tags, other_tags)\n",
    "symcom = cs_metrics.SyMCoM(LID_Tags, PoS_Tags, 'en', 'hi')\n",
    "cm_sentence = cs_metrics.CodeMixSentence(sentence = None, tokens = tokens, LID_Tags = LID_Tags, PoS_Tags = PoS_Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d765b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi_score = metrics.cmi(LID_Tags)\n",
    "mindex_score = metrics.mindex(LID_Tags)\n",
    "lang_entropy_score = metrics.lang_entropy(LID_Tags)\n",
    "spavg_score = metrics.spavg(LID_Tags)\n",
    "i_index_score = metrics.i_index(LID_Tags)\n",
    "burstiness_score = metrics.burstiness(LID_Tags)\n",
    "symcom_pos_tags = symcom.symcom_pos_tags(cm_sentence)\n",
    "symcom_sentence = symcom.symcom_sentence(cm_sentence)\n",
    "\n",
    "print(\"CMI Score:\", cmi_score)\n",
    "print(\"M-Index Score:\", mindex_score)\n",
    "print(\"Lang Entropy Score:\", lang_entropy_score)\n",
    "print(\"SPAVG Score:\", spavg_score)\n",
    "print(\"I-Index Score:\", i_index_score)\n",
    "print(\"Burstiness Score:\", burstiness_score)\n",
    "print(\"\")\n",
    "for tag, score in symcom_pos_tags.items():\n",
    "    print(tag, \":\", score)\n",
    "print(\"SymCom Sentence:\", symcom_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai4bharat.transliteration import XlitEngine\n",
    "e = XlitEngine( beam_width=10, src_script_type = \"indic\")\n",
    "out = e.translit_sentence(\"मैं Hyderabaed में movie देखने जा रहा हूँ\", 'hi')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import numpy as np\n",
    "\n",
    "def predictposSent(model = None, tokenizer = None, sentence= None):\n",
    "  \n",
    "  tokenized_sentence = tokenizer(sentence,return_tensors='pt')\n",
    "\n",
    "  mask = []\n",
    "  prev_id = None\n",
    "  for ind,id in enumerate(tokenized_sentence.word_ids()):\n",
    "    \n",
    "    if id is None:\n",
    "      mask.append(-100)\n",
    "    elif id == prev_id:\n",
    "      mask.append(-100)\n",
    "    elif id != prev_id:\n",
    "      mask.append(id)\n",
    "    prev_id = id\n",
    "\n",
    "\n",
    "  outputs = model(**tokenized_sentence.to(device))\n",
    "\n",
    "  preds = np.argmax(outputs['logits'].cpu().detach().numpy(), axis=2).squeeze()\n",
    "\n",
    "  true_preds = [\n",
    "      model.config.id2label[p] for (p, l) in zip(preds, mask) if l != -100\n",
    "  ]\n",
    "  \n",
    "  return true_preds\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "modelpath = \"prakod/en-hi-pos-tagger-symcom\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(modelpath)\n",
    "model.to(device)\n",
    "\n",
    "sentence =\"मैं Hyderabaed में movie देखने जा रहा हूँ\"\n",
    "\n",
    "tags_normalised = predictposSent(model = model, \n",
    "                                 tokenizer= tokenizer, \n",
    "                                 sentence = sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codemixtoolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
